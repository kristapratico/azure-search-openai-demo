{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-answering system using Azure AI Search and Azure OpenAI\n",
    "\n",
    "This notebook demonstrates how Azure AI Search and Azure OpenAI can be used together to build a simple question-answering system using the Retrieval-Augmented Generation (RAG) pattern. The system is built using the following Azure services:\n",
    "\n",
    "- Azure AI Search\n",
    "- Azure OpenAI\n",
    "\n",
    "In a RAG pattern, queries and responses are coordinated between the search engine and the LLM. A user's question or query is forwarded to both the search engine and to the LLM as a prompt. The search results come back from the search engine and are redirected to an LLM. The response that makes it back to the user is generative AI, either a summation or answer from the LLM. [Learn more](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview#content-retrieval-in-azure-ai-search).\n",
    "\n",
    "### Prerequisites and install instructions\n",
    "- Python 3.8+\n",
    "- An Azure OpenAI service resource\n",
    "    - Ensure you have the `Cognitive Services OpenAI User/Contributor` role assigned to your Azure user/identity on the Azure OpenAI service resource.\n",
    "- An Azure AI Search service resource\n",
    "    - Ensure you have the `Search Index Data User/Contributor` role assigned to your Azure user/identity on the Azure AI Search service resource.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-search-documents==11.6.0b1 openai[datalib] azure-identity python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies and load environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from azure.search.documents import SearchClient\n",
    "from openai import AzureOpenAI\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "AZURE_OPENAI_SERVICE = os.getenv(\"AZURE_OPENAI_SERVICE\")\n",
    "AZURE_OPENAI_CHATGPT_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\")\n",
    "AZURE_SEARCH_SERVICE = os.getenv(\"AZURE_SEARCH_SERVICE\")\n",
    "AZURE_SEARCH_INDEX = os.getenv(\"AZURE_SEARCH_INDEX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a credential for authenticating\n",
    "\n",
    "We will use the Azure Identity library to authenticate with Azure services. The library provides a set of credential classes that can be used to authenticate with Azure services. In this notebook, we will use the `DefaultAzureCredential` class, which will attempt authentication using multiple methods until it finds a valid credential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate clients for Azure AI Search and Azure OpenAI\n",
    "\n",
    "- `SearchClient` class from the `azure-search-documents` library for interacting with a search index in Azure AI Search.\n",
    "- `AzureOpenAI` class from the `openai` library for interacting with the Azure OpenAI service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "    azure_endpoint=f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\",\n",
    "    azure_ad_token_provider=token_provider,\n",
    "    api_version = \"2024-02-01\"\n",
    ")\n",
    "search_client = SearchClient(\n",
    "    endpoint=f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\",\n",
    "    index_name=AZURE_SEARCH_INDEX,\n",
    "    credential=credential,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how many documents are in the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495\n"
     ]
    }
   ],
   "source": [
    "result = search_client.get_document_count()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define method to retrieve the top documents from the index based on the user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_index(query_text: str) -> list:\n",
    "    results = search_client.search(search_text=query_text, top=3)\n",
    "\n",
    "    documents = []\n",
    "    for page in results.by_page():\n",
    "        for document in page:\n",
    "            documents.append(document)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's validate that the method works by passing a sample query to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Does PyCon require wearing a mask?\"\n",
    "documents = search_index(query_text)\n",
    "for document in documents:\n",
    "    print(document)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the method to format the retrieved documents into a format that can be passed to the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sources_content(results):\n",
    "    sources = [\n",
    "        (doc.get(\"sourcepage\", \"\")) + \": \" + doc.get(\"content\", \"\").replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "        for doc in results\n",
    "    ]\n",
    "    content = \"\\n\".join(sources)\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also validate that the method works by passing the documents retrieved in the previous step to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = get_sources_content(documents)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the method to generate an answer to a query using the OpenAI API\n",
    "\n",
    "Here, we will construct a \"conversation\" using the documents retrieved from the search index and pass it to the OpenAI API to generate an answer to the user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query_text: str) -> dict:\n",
    "    documents = search_index(query_text)\n",
    "    content = get_sources_content(documents)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": content\n",
    "\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Python is great!\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query_text\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    chat_completion = openai_client.chat.completions.create(\n",
    "        model=AZURE_OPENAI_CHATGPT_DEPLOYMENT,\n",
    "        messages=messages,\n",
    "        temperature=0.3,\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "    )\n",
    "\n",
    "    return chat_completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a question and get an answer!\n",
    "\n",
    "Using RAG, we can now submit a question to the system an answer enhanced with the search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At PyCon US 2024, one of the talks related to FastAPI is titled \"Combining Django ORM & FastAPI in a Single App.\" This talk is scheduled for Saturday, May 18th, 2024, from 11:15 a.m. to 11:45 a.m. in Ballroom A and will be presented by Mia BajiÄ‡. The talk will focus on the practical implementation of combining Django ORM with FastAPI and share insights from the presenter's experience with this setup.\n"
     ]
    }
   ],
   "source": [
    "query_text = \"What FastAPI talks are there at PyCon?\"\n",
    "completion = process_query(query_text)\n",
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
